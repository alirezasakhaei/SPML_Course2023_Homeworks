{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezasakhaei/SPML_Course2023_Homeworks/blob/main/HW05/NES_and_RND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXavXvaL0-QI",
        "outputId": "df9c632d-02d9-4781-faca-7c6374506126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfYwrKT33NoZ",
        "outputId": "2d3969b0-ff24-4abf-d5e2-df583d5f4bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Z63xrV4PCeabhG9bYrkjb3htNY40F0Pc/myCIFAR10\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/myCIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJqLnnkD4B5u",
        "outputId": "d57f6e60-e3f2-4bbb-9860-36d97ddef786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial_Training\t\t NES_and_RND.ipynb\n",
            "checkpoint\t\t\t __pycache__\n",
            "data\t\t\t\t resnet18_cifar10_model_std\n",
            "FGSM_PGD_and_ADV_Training.ipynb  Saved_Models\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrvAChBVXEf"
      },
      "source": [
        "# **Preface**\n",
        "In this notebook you are going to implement a powerful blackbox attack namely [NES](https://arxiv.org/pdf/1804.08598.pdf) and test it on a regular target model, then you will use a simple but powerful defense called  Random Noise Defense ([RND](https://arxiv.org/pdf/2104.11470.pdf)) against this attack on the same target model in order to check the power of the aforementioned attack in the presence of this so-called defense.\n",
        "You will have to use a **CIFAR10 ResNet18 model** as the target model for this set of experiments.\n",
        "You may want to train a new model or load an already trained model, your choice, but this model must have at least 94% accuracy on CIFAR10 test set as told in the previous exercises.\n",
        "\n",
        "P.S. Don't normalize the data used for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlOdNjoGlp3o"
      },
      "source": [
        "# CIFAR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-cS20kUkmy5w"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as FF\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = FF.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = FF.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = FF.relu(self.bn1(self.conv1(x)))\n",
        "        out = FF.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = FF.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = FF.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = FF.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hXHYBO8EKX0Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# older training (IGNORE)"
      ],
      "metadata": {
        "id": "EpcUSu7W1Oij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYy5Nl_uKdRE",
        "outputId": "8d6ea21e-6b4e-4d1d-f96b-5b4fb159c3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29380862.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTOJ5Ir1LnSu"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X68mARLNlvWg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "\n",
        "    print(f'Loss: {train_loss/(batch_idx+1)}, Acc: {100.*correct/total}')\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f'Loss: {test_loss/(batch_idx+1)}, Acc: {100.*correct/total}')\n",
        "\n",
        "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "# for epoch in range(start_epoch, start_epoch+200):\n",
        "#     train(epoch)\n",
        "#     test(epoch)\n",
        "#     scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRa5GJQbKsBQ"
      },
      "outputs": [],
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTcSfzeJKQs8"
      },
      "outputs": [],
      "source": [
        "# specify the path to your .pth file\n",
        "model_path = './checkpoint/ckpt.pth'\n",
        "\n",
        "# load the model dictionary from the .pth file\n",
        "model_dict = torch.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4qvAAt8LV_d"
      },
      "outputs": [],
      "source": [
        "best_acc = model_dict['acc']\n",
        "start_epoch = model_dict['epoch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2n7rkOLwru",
        "outputId": "7e0ec20b-5146-4da5-dd5b-89b3bfa01988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLBZPGxtLz-x",
        "outputId": "58c417b5-5dfd-4eb6-e99f-ee9d45d93b31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.load_state_dict(model_dict['net'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBn6yFghLrku"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRSSPDebMMtG",
        "outputId": "c2bed633-1891-473a-c114-e902ded1e51d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "120-start_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX063DTXL-Ud"
      },
      "outputs": [],
      "source": [
        "start_epoch = 180\n",
        "for epoch in range(start_epoch, start_epoch+20):\n",
        "    # print(epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArUqoyCSjP4p"
      },
      "source": [
        "# Model Loading and Accuracy Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E3i_aPzwjka2"
      },
      "outputs": [],
      "source": [
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6kllJ-ZBjTS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a337ec10-dc10-4761-cbf8-9dae3d0b10da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Model\n",
        "device = torch.device('cuda')\n",
        "model = ResNet18()\n",
        "model = model.to(device)\n",
        "model = torch.nn.DataParallel(model)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "model.load_state_dict(torch.load('checkpoint/ckpt.pth')['net'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVG3iD9jj15j",
        "outputId": "25be7748-cf8d-4a72-869f-350e3fad1b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=False, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=False, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wrOv8uCj7t5",
        "outputId": "7408e37e-dc6c-4a67-c011-905fe037b8d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is 0.9219\n"
          ]
        }
      ],
      "source": [
        "acc = test(model, testloader)\n",
        "print(f'Accuracy of the model is {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isdk2N3kZE4k"
      },
      "source": [
        "# **Natural Evolutionary Strategies (NES)**\n",
        "\n",
        "Firstly complete the code for the attack itself and then the add_Gaussian method used for the Random Noise Defense in the NES attack class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KOtCzRz9VS8i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch as ch\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import json\n",
        "import pdb\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import DataParallel\n",
        "from torch.nn.modules import Upsample\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "CLASSIFIERS = {\n",
        "    \"resnet18\": (models.resnet50, 224),\n",
        "}\n",
        "\n",
        "NUM_CLASSES = {\n",
        "    \"cifar10\": 10,\n",
        "}\n",
        "\n",
        "# Set the path to your dataset\n",
        "CIFAR10_PATH = \"./data\"\n",
        "\n",
        "if CIFAR10_PATH == \"\":\n",
        "  raise ValueError(\"Please fill out the path to Cifar10!\")\n",
        "\n",
        "class NES():\n",
        "\n",
        "  def __init__(self, model_to_fool, args, dataset_size, RND_coefficient, device):\n",
        "\n",
        "\n",
        "      if args != None:\n",
        "        self.args = args\n",
        "      else:\n",
        "        self.max_queries = 10000\n",
        "        self.fd_eta = 0.01\n",
        "        self.image_lr = 0.01\n",
        "        self.mode = \"linf\"\n",
        "        self.json_config = None\n",
        "        self.epsilon = 0.05\n",
        "        self.batch_size = 10\n",
        "        self.log_process = \"store_true\"\n",
        "        self.gradient_iters = 15\n",
        "        self.total_images = 10000\n",
        "        self.classifier = 'resnet18'\n",
        "        self.args = {'max_queries': self.max_queries,\n",
        "          'fd_eta': self.fd_eta,\n",
        "          'image_lr': self.image_lr,\n",
        "          'mode': self.mode,\n",
        "          'json_config': self.json_config,\n",
        "          'epsilon': self.epsilon,\n",
        "          'batch_size': self.batch_size,\n",
        "          'log_progress': self.log_progress,\n",
        "          'gradient_iters': self.gradient_iters,\n",
        "          'total_images': self.total_images,\n",
        "          'classifier': self.classifier,\n",
        "          }\n",
        "      self.model_to_fool = model_to_fool\n",
        "      self.dataset_size = dataset_size\n",
        "      self.RND_coefficient = RND_coefficient\n",
        "      self.device = device\n",
        "      if self.device == 'cuda':\n",
        "        ch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "      else:\n",
        "        ch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "      if self.dataset_size == 32:\n",
        "        self.channel_size = 3\n",
        "      else:\n",
        "        raise ValueError(\"Please check out the dataset_size parameter...\")\n",
        "\n",
        "\n",
        "  \"\"\"For setting up the Random Noise Defense\"\"\"\n",
        "\n",
        "  def add_Gausian(self, input_image, coeff):\n",
        "    # Firstly define a random epsilon with the input image shape\n",
        "    # Remember that it should be a float\n",
        "    # Add the epsilon with the proper coefficient to the input image\n",
        "    # Don't forget to clamp it between the right values\n",
        "    # P.S. Remember to convert everything to the right device\n",
        "    #############################\n",
        "    # Your code goes here\n",
        "    epsilon = ch.randn_like(input_image).to(device=input_image.device)\n",
        "    # epsilon /= (self.norm(epsilon)/math.sqrt(input_image.nelement()))\n",
        "    return ch.clamp(input_image + coeff*epsilon, 0, 1)\n",
        "    #############################\n",
        "\n",
        "\n",
        "  def generate(self):\n",
        "      dataset = None\n",
        "      if self.dataset_size == 32:\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(self.dataset_size), transforms.CenterCrop(self.dataset_size),])\n",
        "        dataset = torchvision.datasets.CIFAR10(root = CIFAR10_PATH, train = False, download = False, transform = transform)\n",
        "      else:\n",
        "        raise ValueError(\"Please check out the dataset_size parameter...\")\n",
        "\n",
        "      dataset_loader = DataLoader(dataset, batch_size=self.args[\"batch_size\"])\n",
        "      total_correct, total_adv, total_queries = 0, 0, 0\n",
        "      for i, (images, targets) in enumerate(dataset_loader):\n",
        "          if i*self.args[\"batch_size\"] >= self.args[\"total_images\"]:\n",
        "              break\n",
        "\n",
        "          res = self.make_adversarial_examples(images.to(self.device), targets.to(self.device), self.args, self.model_to_fool, self.dataset_size)\n",
        "          ncc = res['num_correctly_classified'] # Number of correctly classified images (originally)\n",
        "          num_adv = ncc * res['success_rate'] # Success rate was calculated as (# adv)/(# correct classified)\n",
        "          queries = num_adv * res['average_queries'] # Average queries was calculated as (total queries for advs)/(# advs)\n",
        "          total_correct += ncc\n",
        "          total_adv += num_adv\n",
        "          total_queries += queries\n",
        "          print(\"i: \" + str(i))\n",
        "\n",
        "          if i == 18:\n",
        "              break\n",
        "\n",
        "      print(\"-\"*80)\n",
        "      if total_adv != 0:\n",
        "        print(\"Final Success Rate: {succ} | Final Average Queries for Successful Adv Examples: {aq}\".format(\n",
        "                aq=int(total_queries/total_adv),\n",
        "                succ=total_adv/total_correct))\n",
        "      else:\n",
        "        \"\"\"If total adversarial examples is zero then we won't print any avg number of queries for success\n",
        "        because we had no success and the avg number of queries has exceeded the budget\"\"\"\n",
        "        print(\"Final Success Rate: {succ} \".format(\n",
        "                # aq = total_queries,\n",
        "                succ=total_adv/total_correct))\n",
        "      print(\"-\"*80)\n",
        "      # return self.adversarial_images\n",
        "\n",
        "  def norm(self, t):\n",
        "      assert len(t.shape) == 4\n",
        "      norm_vec = ch.sqrt(t.pow(2).sum(dim=[1,2,3])).view(-1, 1, 1, 1)\n",
        "      norm_vec += (norm_vec == 0).float()*1e-8\n",
        "      return norm_vec\n",
        "\n",
        "  ###\n",
        "  # Different optimization steps\n",
        "  # All take the form of func(x, g, lr)\n",
        "  # eg: exponentiated gradients\n",
        "  # gd: gradient descent\n",
        "  # l2/linf: projected gradient descent\n",
        "  ###\n",
        "\n",
        "\n",
        "  def eg_step(self, x, g, lr):\n",
        "      real_x = (x + 1)/2 # from [-1, 1] to [0, 1]\n",
        "      pos = real_x*ch.exp(lr*g)\n",
        "      neg = (1-real_x)*ch.exp(-lr*g)\n",
        "      new_x = pos/(pos+neg)\n",
        "      return new_x*2-1\n",
        "\n",
        "  def linf_step(self, x, g, lr):\n",
        "      return x + lr*ch.sign(g)\n",
        "\n",
        "  def l2_prior_step(self, x, g, lr):\n",
        "      new_x = x + lr*g/self.norm(g)\n",
        "      norm_new_x = self.norm(new_x)\n",
        "      norm_mask = (norm_new_x < 1.0).float()\n",
        "      return new_x*norm_mask + (1-norm_mask)*new_x/norm_new_x\n",
        "\n",
        "  def gd_prior_step(self, x, g, lr):\n",
        "      return x + lr*g\n",
        "\n",
        "  def l2_image_step(self, x, g, lr):\n",
        "      return x + lr*g/self.norm(g)\n",
        "\n",
        "  ##\n",
        "  # Projection steps for l2 and linf constraints:\n",
        "  # All take the form of func(new_x, old_x, epsilon)\n",
        "  ##\n",
        "\n",
        "  def l2_proj(self, image, eps):\n",
        "      orig = image.clone()\n",
        "      def proj(new_x):\n",
        "          delta = new_x - orig\n",
        "          out_of_bounds_mask = (self.norm(delta) > eps).float()\n",
        "          x = (orig + eps*delta/self.norm(delta))*out_of_bounds_mask\n",
        "          x += new_x*(1-out_of_bounds_mask)\n",
        "          return x\n",
        "      return proj\n",
        "\n",
        "  def linf_proj(self, image, eps):\n",
        "      orig = image.clone()\n",
        "      def proj(new_x):\n",
        "          return orig + ch.clamp(new_x - orig, -eps, eps)\n",
        "      return proj\n",
        "\n",
        "  ##\n",
        "  # Main functions\n",
        "  ##\n",
        "\n",
        "  def make_adversarial_examples(self, image, true_label, args, model_to_fool, DATASET_SIZE):\n",
        "      '''\n",
        "      The main process for generating adversarial examples with priors.\n",
        "      '''\n",
        "      # Initial setup\n",
        "      prior_size = DATASET_SIZE\n",
        "      upsampler = Upsample(size=(DATASET_SIZE, DATASET_SIZE))\n",
        "      total_queries = ch.zeros(args[\"batch_size\"])\n",
        "      prior = ch.zeros(args[\"batch_size\"], self.channel_size, prior_size, prior_size)\n",
        "      dim = prior.nelement()/args[\"batch_size\"]\n",
        "      image_step = self.l2_image_step if args[\"mode\"] == 'l2' else self.linf_step\n",
        "      proj_maker = self.l2_proj if args[\"mode\"] == 'l2' else self.linf_proj\n",
        "      proj_step = proj_maker(image, args[\"epsilon\"])\n",
        "\n",
        "      # Loss function\n",
        "      criterion = ch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "      def normalized_eval(x):\n",
        "          x_copy = x.clone()\n",
        "\n",
        "          # You can comment or uncomment the code needed for a specific case\n",
        "          \"\"\"################## Normal prediction ##################\"\"\"\n",
        "          # x_copy = ch.clamp(x_copy, 0, 1)\n",
        "          # return self.model_to_fool(x_copy)\n",
        "\n",
        "          \"\"\"################## Prediction using random noise defense ##################\"\"\"\n",
        "          x_copy_noisy = self.add_Gausian(x_copy, self.RND_coefficient)\n",
        "          x_copy_noisy = ch.clamp(x_copy_noisy, 0, 1)\n",
        "          return self.model_to_fool(x_copy_noisy)\n",
        "\n",
        "      L = lambda x: criterion(normalized_eval(x), true_label)\n",
        "\n",
        "      losses = L(image)\n",
        "\n",
        "      # Original classifications\n",
        "      orig_images = image.clone()\n",
        "\n",
        "      # You can comment or uncomment the code needed for a specific case\n",
        "      \"\"\"##################Normal prediction##################\"\"\"\n",
        "      orig_classes = self.model_to_fool(orig_images).argmax(1).to(self.device)\n",
        "\n",
        "      \"\"\"################## Prediction using random noise defense ##################\"\"\"\n",
        "      # image_noisy = self.add_Gausian(image, self.RND_coefficient)\n",
        "      # image_noisy = ch.clamp(image_noisy, 0, 1)\n",
        "      # orig_classes = self.model_to_fool(image_noisy).argmax(1).to(self.device)\n",
        "\n",
        "      correct_classified_mask = (orig_classes == true_label).float()\n",
        "      total_ims = correct_classified_mask.sum()\n",
        "      not_dones_mask = correct_classified_mask.clone()\n",
        "\n",
        "      t = 0\n",
        "      while not ch.any(total_queries > args[\"max_queries\"]):\n",
        "          t += args[\"gradient_iters\"]*2\n",
        "          if t >= args[\"max_queries\"]:\n",
        "              break\n",
        "\n",
        "          prior = ch.zeros_like(image)\n",
        "          for _ in range(args[\"gradient_iters\"]):\n",
        "\n",
        "              #############################\n",
        "              # Your code goes here\n",
        "              # Define a tensor of random Gaussian noise with the input image shape\n",
        "              exp_noise = ch.randn_like(image)\n",
        "              # Then devide this tensor by (dim**0.5)\n",
        "              exp_noise = exp_noise / (dim ** 0.5)\n",
        "              # Now add and subtract the defined noise with the fd_eta coefficient with the original image\n",
        "              fd_eta = self.args['fd_eta']\n",
        "              est_deriv = (L(image + fd_eta*exp_noise) - L(image - fd_eta*exp_noise))/fd_eta\n",
        "              # Finally build the gradient estimation of the loss using the finite difference method\n",
        "              #############################\n",
        "\n",
        "              prior += est_deriv.view(-1, 1, 1, 1)*exp_noise\n",
        "\n",
        "          # Preserve images that are already done,\n",
        "          # Unless we are specifically measuring gradient estimation\n",
        "          prior = prior*not_dones_mask.view(-1, 1, 1, 1)\n",
        "\n",
        "          ## Update the image:\n",
        "          # take a pgd step using the prior\n",
        "          new_im = image_step(image, upsampler(prior*correct_classified_mask.view(-1, 1, 1, 1)), args[\"image_lr\"])\n",
        "          image = proj_step(new_im)\n",
        "          image = ch.clamp(image, 0, 1)\n",
        "\n",
        "          if args[\"mode\"] == 'l2':\n",
        "              if not ch.all(self.norm(image - orig_images) <= args[\"epsilon\"] + 1e-3):\n",
        "                  pass\n",
        "                  # pdb.set_trace()\n",
        "          else:\n",
        "              if not (image - orig_images).max() <= args[\"epsilon\"] + 1e-3:\n",
        "                pass\n",
        "                  # pdb.set_trace()\n",
        "\n",
        "          ## Continue query count\n",
        "          total_queries += 2*args[\"gradient_iters\"]*not_dones_mask\n",
        "          not_dones_mask = not_dones_mask*((normalized_eval(image).argmax(1) == true_label).float())\n",
        "\n",
        "          ## Logging and stuff\n",
        "\n",
        "          # new_losses = L(image)\n",
        "          success_mask = (1 - not_dones_mask)*correct_classified_mask\n",
        "          num_success = success_mask.sum()\n",
        "          if num_success != 0:\n",
        "            success_queries = ((success_mask*total_queries).sum()/num_success).cpu().item()\n",
        "          else:\n",
        "            success_queries = ((success_mask*total_queries).sum()).cpu().item()\n",
        "          \"\"\"If num_success == 0 it means that the number of successful adv examples was zero (No adv examples could be made!)\n",
        "          so success queries must not be printed \"\"\"\n",
        "\n",
        "          current_success_rate = (num_success/correct_classified_mask.sum()).cpu().item()\n",
        "          #not_done_loss = ((new_losses*not_dones_mask).sum()/not_dones_mask.sum()).cpu().item()\n",
        "          max_curr_queries = total_queries.max().cpu().item()\n",
        "          # if args[\"log_progress\"]:\n",
        "          #   print(\"Queries: %d (%d) | Success rate: %f | Average queries: %f\" % (max_curr_queries , t, current_success_rate, success_queries))\n",
        "\n",
        "          if current_success_rate == 1.0:\n",
        "              break\n",
        "\n",
        "      return {\n",
        "              'average_queries': success_queries,\n",
        "              'num_correctly_classified': correct_classified_mask.sum().cpu().item(),\n",
        "              'success_rate': current_success_rate,\n",
        "              'images_orig': orig_images.cpu().numpy(),\n",
        "              'images_adv': image.cpu().numpy(),\n",
        "              'all_queries': total_queries.cpu().numpy(),\n",
        "              'correctly_classified': correct_classified_mask.cpu().numpy(),\n",
        "              'success': success_mask.cpu().numpy()\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdQXoR3YS58"
      },
      "source": [
        "# **Attack Arguments Setup**\n",
        "\n",
        "**Write a report and indicate the success rate and average number of qureies for sections A and B.**\n",
        "\n",
        "A) Now you must launch the attack using different values;\n",
        "For the whole CIFAR10 test set, first on the regular target model and without the Random Noise Defense, with fd_eta parameter of 0.01 and 0.001, using \"linf\" mode (2 results).\n",
        "\n",
        "B) Then apply the Random Noise Defense on the target model with RND_coefficient of 0.01 and 0.02 against NES with fd_eta parameter of 0.01 and 0.001 again using the \"linf\" mode (4 results).\n",
        "\n",
        "Analyse and compare the results of both sections in your report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr72hNYhXO7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7925ab-701d-4c3e-be12-dbab5ba083bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 0\n",
            "i: 1\n",
            "i: 2\n",
            "i: 3\n",
            "i: 4\n",
            "i: 5\n",
            "i: 6\n",
            "i: 7\n",
            "i: 8\n",
            "i: 9\n",
            "i: 10\n",
            "i: 11\n",
            "i: 12\n",
            "i: 13\n",
            "i: 14\n",
            "i: 15\n"
          ]
        }
      ],
      "source": [
        "budget = 1000\n",
        "target_model_arch = 'resnet18'\n",
        "dataset_size = 32\n",
        "\n",
        "args = {'max_queries': budget,\n",
        "              'fd_eta': 0.01,\n",
        "              'image_lr': 0.01,\n",
        "              'mode': 'linf',\n",
        "              'json_config': None,\n",
        "              'epsilon': 0.05,\n",
        "              'batch_size': 512,\n",
        "              'log_progress': \"store_true\",\n",
        "              'gradient_iters': 15,\n",
        "              'total_images': 10000,\n",
        "              'classifier': target_model_arch,\n",
        "              }\n",
        "\"\"\"\n",
        "RND_coefficient = ?\n",
        "device = ?\n",
        "target_model.eval()\n",
        "\"\"\"\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Launch the attack using the NES class and its generate method\n",
        "    #############################\n",
        "    # Your code goes here\n",
        "    attack = NES(model, args, dataset_size, 0.02, 'cuda')\n",
        "    back = attack.generate()\n",
        "    #############################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}